---
title: "KBhave_621FinalProject.Rmd"
author: 'The CrystalGazer : Kumudini Bhave'
date: "May 25, 2017"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
  html_document:
    fontsize: 35pt
    highlight: pygments
    theme: cerulean
    toc: yes
subtitle: 'Regression Models : Predicting Glass Type'
---



\newpage 

# **Regression Models : Glass Type Prediction**

********

## Objective

This is an R Markdown document for providing documentation for performing **Regression** by  **Data Exploration, Transformation, Analysis And Modelling and Prediction for the Glass data** to predict the type of glass based on given certain properties of the glass.

This dataset has been taken from the UCI machine learning datasets website  https://archive.ics.uci.edu/ml/datasets/glass+identification.

I have chosen this dataset to study the regressions for more than one values of response variable.
This data has been recorded in 1987. The primary motivation of the study of different types of glass has been criminal investigation. A curiosity to understand and explore how a study of glass types could lead to insights to satisfy such motivation leads me to choose this for my final project study.

The analysis for this study is organized as follows:

1. Generate several data visualizations to understand the underlying data;
2. Perform data transformations as needed;
3. Develop models to help classify data and Apply models to test data 
4. Compare models.

## Background

Glass can be found in most localities. It is produced in a wide variety of forms and compositions, and these affect the properties of this material. It can occur as evidence when it is broken during the commission of a crime. Broken glass fragments ranging in size from large pieces to tiny shards may be transferred to and retained by nearby persons or objects. The mere presence of fragments of glass on the clothing of an alleged burglar in a case involving entry through a broken window may be significant evidence if fragments are found. The significance of such evidence will be enhanced if the fragments are determined to be indistinguishable in all measured properties from the broken window. On the other hand, if the recovered fragments differ in their measured properties from the glass from the broken window, then that window can be eliminated as a possible source of the glass on the subject's clothing.

Glass is technically defined as "The inorganic product of fusion which has cooled to a rigid condition without crystallizing"

Some specialty glasses such as optical glass, novelty glass, or glass that is difficult to melt are produced in pot furnaces or day tanks.

Laminated glass is produced by heat-sealing thin layers of plastic between two or more panes of heat-strengthened glass. In the United States, laminated glass must be installed in the windshields of vehicles, and tempered glass must be installed in the side and rear windows

When a glass object breaks, fragments can be ejected from the object in all directions (Pounds and Smalldon 1978), including backward toward the direction of the breaking force (Nelson and Revell 1967). During experimental studies, glass fragments have been recovered from up to four meters away from a breaking glass object (Francis 1993; Locke and Unikowski 1991). Glass fragments can be transferred onto anything within this distance. 

The number of glass fragments that can be transferred is controlled by a number of factors:

-The closer something is to the breaking glass, the more likely it is to have glass fragments transferred to it (Allen and Scranage 1998). The number of fragments transferred decreases with distance from the break (Pounds and Smalldon 1978).

-The person breaking a window will have more glass on him or her than a bystander, and the more blows required to break out the glass, the more glass that will be transferred (Allen et al. 1998b).

-The number of glass fragments generated by a break is independent of the size and thickness of the window but increases with greater damage to the glass (Locke and Unikowski 1992).

-Whether the glass that is deposited on clothing persists to be recovered by a forensic examiner depends upon additional factors:

-Less glass is retained on slick clothing, such as nylon jackets, than on rough clothing, such as wool sweaters. Wet clothing retains more glass than dry clothing (Allen et al. 1998b).

-Glass fragments fall off clothing over time, and larger pieces fall off before smaller pieces (Cox et al. 1996a, 1996b, 1996c; Hicks et al. 1996; Hoefler et al. 1994).

-Glass falls off faster if the person wearing the clothing is active (Batten 1989; Cox et al. 1996c; Hicks et al. 1996).
It should be noted, however, that the transfer and persistence of glass is highly variable

A primary transfer-is a transfer from the broken glass object to something else. Primary transfer also can occur when a person or object comes into contact with previously broken glass (Allen et al. 1998a). Additionally, there can be secondary transfer of glass between people and objects, such as when glass is transferred from a person to a vehicle sea
During a glass examination, it cannot be positively determined whether the glass fragments found on an object were acquired through primary transfer, secondary transfer, or through contact with previously broken glass

**Optical Properties such as Refractive index (n):**

It is a unitless measure of the speed of light in a transparent medium and is defined by Snell's law as the ratio of the velocity of light in a vacuum to the velocity of the wave in the transparent medium (Stoiber and Morse 1981). Refractive index is a function of chemical composition and atomic arrangement 
Refractive index is the most commonly measured property in the forensic examination of glass fragments (Koons et al. 2002), because:
- Precise refractive indices can be measured rapidly on the small fragments typically found in casework.
- It can aid in the characterization of glass.
- It provides good discrimination potential. (Koons et al. 2002)


**Elemental Analysis such as chemical composition of glass :**

Manufacturers control the concentrations of many chemical elements to impart specific properties to their glass product. The chemical analysis remains the best means for differentiating glass specimens 


**The Crime Investigation Aspect :**

Glass is formidable, forensically speaking. Formidable because - despite the fact that once smashed, it fragments into millions of tiny shards, from the large to the microscopic - it is nearly impossible for any suspect involved in a scene where it is present not to take away a trace. A glass impact will shower fragments into a surprisingly large radius - up to around three metres. If a forensic investigator trained in glass recovery manages to trace an intruder and seize some clothes - if he was wearing them at the time - there's a significant chance it will have glass that would tie him to the scene in question. Glass can also be found in some unlikely places too - like our burglar's hair, ears, underneath the fingernails or even in the skin.

*1. Looking back: the refractive index*

This highly accurate test relies on the reflectivity of the recovered and control samples being compared. Light is shone on the recovered glass and a control sample from the window itself. The test measures how much light is reflected and how much is absorbed by the sample. If it matches that of the control sample - its likely to be from the same window or fixture.

*2. The stuff inside: chemical analysis*

Analysing the specimen sample against the control using scanning electron microscopy enables an astute investigator to determine if the physical constituents of the samples are the same. It provides detailed information on the elements used in the glass's composition, such as the composition of sand and other chemicals. If the physical composition of the specimen matches the control sample - it is likely to be from the same place.

Glass is also immensely useful, forensically speaking, in other ways. If a bullet was fired through a window, for example, the pattern of glass fracture may tell us the trajectory from which it entered. A burglar may cut himself on a broken window entering or exiting a building, leaving tell-tale DNA evidence at the scene. And as every frustrated window cleaner knows, glass is great for showing up everyone's favourite piece of tell tale evidence - fingerprints.

*Glass analysis, hence, is another invaluable tool in our arsenal for linking suspects to a crime scene.* 

\newpage

## Technical Summary


This analysis demonstrates several analytic techniques to examine various the optical and chemical properties of the glass, and classify the glass type.
The various techniques used in this study are multinomial logistic regression, random forests, conditional inference trees, linear discriminant analysis.
The best performing model , Random Forest model, gave an accuracy of 86%.

The most influential predictos :????


To facilitate the model selection through crossvalidation we will be randomly dividing the glass data into a training set that contains 70% of the data and a test set that contains 30% of the data.


## Exploratory Data Analysis

The first step in any analysis is to obtain the dataset and codebook. Both the dataset and the codebook can be downloaded for free from the UCI website. 

### Glass DataSet Evaluation

The Glass data set contains 214 cases, including an indentification variable (INDEX), 9  predictors, and one response
variable. Each case is a commercially available glass, with the response variable being the type of glass, depending upon the chemical composition and the refractive index.


Of the 9 predictor variables, 8 are related to chemical properties ofthe glass and 1 is the physical property of refractive index of glass.


The response variable is:

**GlassType**: This indicates the type of glass. 

The various potential predictor variables in the original dataset under study are :

Predictor Variables | Definition
------------------- | ---------------------------------------------------------------------------------------------------
Id | number: 1 to 214 
RI | Refractive Index 
Na | Sodium (unit measurement: weight percent in corresponding oxide,
Mg | Magnesium
Al | Aluminum 
Si | Silicon 
K | Potassium 
Ca | Calcium 
Ba | Barium 
Fe | Iron 
Type of glass | (class attribute) Values given table below

Value | Type Of Glass
------ | -----------------------------------
 1 | building_windows_float_processed 
 2 | building_windows_non_float_processed 
 3 | vehicle_windows_float_processed 
 4 | vehicle_windows_non_float_processed (none in this database)  5 |
 5 | containers 
 6 | tableware 
 7 | headlamps



### Loading the Dataset :

```{r warning=FALSE, comment=FALSE, message=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=200)}
knitr::opts_chunk$set(message = FALSE, echo=TRUE)


# Library for data display in tabular format

#library(DT)
library(tidyr)
library(dplyr)
library(readr)
# For string extractions
library(stringr)
# Library for plotting
library(ggplot2)
library(gridExtra)
library(Amelia)
library(ggmosaic)

library(corrplot)
library(e1071)
library(data.table)
# statistical packages
library(knitr)
library(caret)
library(pander)
# ROC 
library(glmnet)
library(mlogit)
library(pROC)
library(car)
library(bestglm)
library(vcd)
library(MASS)
library(forecast)
# Loading RCurl package to help scrape data from web (stored on GitHub).
library(RCurl)

# Loading plyr package to help map abbreviated values to explained.
library(plyr)
```


```{r results='hide', tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Getting data 

### Extracting Raw Data From GitHub Data File And Reading In CSV Format

data.giturl <- "https://raw.githubusercontent.com/DataDriven-MSDA/DATA621/master/Final/glass.data"
glass.gitdata <- getURL(data.giturl)
glass.gitdata.csv <- read.csv(text=glass.gitdata, header=F, sep=",",stringsAsFactors = FALSE)

#View(glass.gitdata.csv)

```



### Renaming Attributes 

We name the attributes per the data description/codebook.

```{r results='hide', tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Naming the Attributes selected for study
colnames(glass.gitdata.csv) <- c("ID","RI","Na","Mg","Al","Si","K","Ca","Ba","Fe", "GlassType")



# Verifying the number of attributes
length(glass.gitdata.csv)
# Verifying the number of observations selected
nrow(glass.gitdata.csv)




```

I have removed the Id column and work only with potential predictors.

```{r results='hide', tidy=TRUE, tidy.opts=list(width.cutoff=80)}

traindataorig <- dplyr::select(glass.gitdata.csv, -1)


nrow(traindataorig)
ncol(traindataorig)
#View(traindataorig)
#View(traindata)
#View(evaldata)
#head(traindataorig)
```



\newpage 


### Data Exploration

Below is the summary of the potential predictor variables and the response variable "GlassType" in the dataset.


#### Response Variable:

**GlassType**

It is found that the "GlassType" response variable has discrete values ranging from 1 to 7.Each Type represent whether it is float processed or not, and if it for vehicle or window , container, tableware or lamp. The variable is categorical in nature.
There is no particular order for these values. GlassType has 214 observations of glass which constitutes float processed glass for windows constitutes 32.71% of the total observations. The highest number of glass type is Type 2 which is non float processed windows glass constituting about 35.51%

Least number is that of Type 6 which is 4.2% for tableware type of glass.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}

pander(table(traindataorig$GlassType), caption = "Response Variable : GlassType")
pander(table(traindataorig$GlassType)/sum(table(traindataorig$GlassType)), caption = "Frequency Table : GlassType")

```



```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


# Histogram for the response variable GlassType
#par(mfrow=c(1,2))
ggplot(traindataorig, aes(x=GlassType)) + geom_histogram() + ggtitle("Histogram Response Variable: GlassType")


```


#### Predictor Variables : 

Let's take a look at the summary of the potential predictor variables.


```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Summary Table

means <- sapply(traindataorig, mean)
medians <- sapply(traindataorig, median)
IQRs <- sapply(traindataorig, IQR)
skews <- sapply(traindataorig, skewness)
sds <- sapply(traindataorig, sd)
cors <- as.vector(cor(traindataorig$GlassType, traindataorig[,1:ncol(traindataorig)]))

header <- (c("MEAN", "MEDIAN", "IQR", "SKEWNESS", "STD.DEV" , "CORRELATION"))

datasummary <- as.data.frame(cbind(means, medians, IQRs, skews, sds,cors))
datasummary <- round(datasummary, 2)
colnames(datasummary) <- header
pander(datasummary, caption = "Summary of Glass Data Variables")

```

The predictor variables are numerical. Plotted below are the distributions of each of the variables.



```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


# Continuous Predictor Distributions

contipred <- traindataorig %>% dplyr::select(-c(GlassType))

meltedc <- melt(contipred)

ggplot(meltedc, aes(value)) + geom_bar(aes(fill = variable, col = variable), alpha = 0.5, show.legend = FALSE) + facet_wrap(~variable, scale="free")+ ggtitle("Distribution of Continuous Variables \n")




```

It is observed that the **K** i.e. Potassium, **Ba** i.e Barium, **Fe** i.e. Iron elements are heavily rightskewed. Whether the tranformations of these could help form a better correlation with the response  variable GlassType would be further explored.
**Ca** Calcium, is very lightly right skewed.
The other predictors are roughly normally distributed.

*********


### Box Plot for Predictors by GlassType

The distribution of Predictor Variables and the magnitude of the  constituency of each chemical component /refractive index in Glass per GlassType can be observed below from the boxplots.
![Refractive Index For Glass Types](https://raw.githubusercontent.com/DataDriven-MSDA/DATA621/master/Final/RI.jpeg)


While this database does  not contain any data on GlassType 4 which is non float processed vehicle glass, the boxplots show distributions per other type of glasses.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


#traindataorig$GlassType <- as.factor(traindataorig$GlassType)


RIbox <- ggplot(traindataorig, aes(factor(GlassType), RI, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Refractive Index vs Glass Type\n")

Nabox <- ggplot(traindataorig, aes(factor(GlassType), Na, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Sodium vs Glass Type\n")

Mgbox <- ggplot(traindataorig, aes(factor(GlassType), Mg, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Magnesium vs Glass Type\n")


Albox <- ggplot(traindataorig, aes(factor(GlassType), Al, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Aluminium vs Glass Type\n")

Sibox <- ggplot(traindataorig, aes(factor(GlassType), Si, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Silicon vs Glass Type\n")

Kbox <- ggplot(traindataorig, aes(factor(GlassType), K, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Potassium vs Glass Type\n")

Cabox <- ggplot(traindataorig, aes(factor(GlassType),Ca, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Calcium vs Glass Type\n")

Babox <- ggplot(traindataorig, aes(factor(GlassType), Ba, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Barium vs Glass Type\n")

Febox <- ggplot(traindataorig, aes(factor(GlassType), Fe, colour=factor(GlassType))) + geom_boxplot() +ggtitle("Iron vs Glass Type\n")

par(mfrow = c(1,2))
RIbox
Nabox

par(mfrow = c(1,2))
Mgbox
Albox

par(mfrow = c(1,2))
Sibox
Kbox

par(mfrow = c(1,2))
Cabox
Babox


Febox



#grid.arrange(RIbox,Nabox,Mgbox,Albox,Sibox,Kbox,Cabox,Babox,Febox,ncol=3,nrow=3)


```


From the Table above , it is intuitive that the higher **refractive index** is associated with container type of glass as compared to other types of glasses and that is what is observed in boxplot of RI vs GlassType for Type 5 glass.

It is intuitive that **Sodium (Na)** content is least for the container type of glasses ( as observed in box plot of Na) as  Container glass is a soda-lime glass that is a slight variation on flat glass, which uses more alumina and calcium, and less sodium and magnesium which are more water-soluble. This makes it less susceptible to water erosion.
It is high for the Type 6 tableware and Type 7 headlamps


The Vehicle and the Window glasses both float and non float processed are high in Magnesium content.

The **Si (Silica) and Al(Aluminium )** in its Alumina form stand heat expansion much better than window glass.[10] Used for chemical glassware, cooking glass, car head lamps, etc. Borosilicate glasses (e.g. Pyrex, Duran) have as main constituents silica and boron trioxide. They have fairly low coefficients of thermal expansion.
Expectedly these seem to be higher for container , tableware applications.

Stabilizers make the glass strong and water resistant. Calcium carbonate, often called calcined limestone, is a stabilizer. Without a stabilizer, water and humidity attack and dissolve glass. It is observed that **Ca** Calcium is higher in container type of glass.

The Ba Barium content of glass is for the crystalline nature and is an alternative material to lead which can have health hazards.
Alkali-barium Silicate Glass are also use in Televisiosn.
Without this type of glass, watching TV would be very dangerous. A television produces X-rays that must be absorbed, otherwise they could in the long run cause health problems. The X-rays are absorbed by glass with minimum amounts of heavy oxides (lead, barium or strontium). Lead glass is commonly used for the funnel and neck of the TV tube, while glass containing barium is used for the screen. From the boxplots, it is observed to have high potential in headlamp glass.


\newpage 

## Data Preparation

### Missing Data

The data is pretty clean with no NAs and no outliers. But this dataset does not have any data for Type 4 Vehicle non float processed glass.


### Correlation Matrix.

The correlation matrix shows **Na** Sodium , **Mg** Magnesium, **Al** Aluminium , **Ba** are the most correlated in deciding the GlassType.
The **K** Potassium content , **Ca** calcium content are not so significantly coorelated.
**Si** Silica, **Fe** Iron,  and physcial Refractive Index property have some amount of correlation to the GlassType.

In the models built , I will see how much of these physical/chemical properties hold true significance in determining and correctly predicting the GlassType.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}


cormat<-as.matrix(cor(traindataorig, use = "pairwise.complete.obs"))
corrplot(cormat,  method="color", tl.cex=0.7, addCoef.col = "black", addCoefasPercent = TRUE)


```



### Transformations

Here, I have tried to see the BoxCox method suggests any transformations.
Below is a table depicting the possible log, sqrt, reiprocal transformations for the variables and possible change/no change in the correlation factor w.r.t the response variable GlassType.


```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


#BOXCOX lambda computing for each variable

lambda.RI <- BoxCox.lambda(traindataorig$RI) # Indicates Using As Is , Y^1

lambda.Na <- BoxCox.lambda(traindataorig$Na) # Indicates Using As Is , Y^1

lambda.Mg <- BoxCox.lambda(traindataorig$Mg) # Indicates Using As Is , Y^1

lambda.Al <- BoxCox.lambda(traindataorig$Al) # Indicates Using As Is , Y^1

lambda.Si <- BoxCox.lambda(traindataorig$Si) # Indicates Using As Is , Y^1

lambda.K <- BoxCox.lambda(traindataorig$K) # Indicates Using As Is , Y^1

lambda.Ca <- BoxCox.lambda(traindataorig$Ca) # Indicates Using As Is , Y^1

lambda.Ba <- BoxCox.lambda(traindataorig$Ba) # Indicates Using As Is , Y^1

lambda.Fe <- BoxCox.lambda(traindataorig$Fe) # Indicates Using As Is , Y^1

lambda.GlassType <- BoxCox.lambda(traindataorig$GlassType) # Indicates Using As Is , Y^1


lambdaX <- rbind(lambda.RI,lambda.Na,lambda.Mg,lambda.Al,lambda.Si,lambda.K,lambda.Ca,lambda.Ba,lambda.Fe,lambda.GlassType)




```




```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Transformation Matrix, to see the possibility of any improvement in correlation to GlassType

cors2 <- as.vector(cor(traindataorig$GlassType, traindataorig[,1:ncol(traindataorig)]))

log_cors <- as.vector(cor(traindataorig$GlassType, log(traindataorig[,1:ncol(traindataorig)])))

sqrt_cors <- as.vector(cor(traindataorig$GlassType, sqrt(traindataorig[,1:ncol(traindataorig)])))

recip_cors <- as.vector(cor(traindataorig$GlassType, (1/traindataorig[,1:ncol(traindataorig)])))

header2 <- (c("No Transform", "LOG", "SQ.ROOT", "1/X","Lambda"))

transforms <- as.data.frame(cbind(cors2, log_cors, sqrt_cors, recip_cors, lambdaX))
transforms <- round(transforms, 2)
rownames(transforms) <- colnames(traindataorig)
colnames(transforms) <- header2
pander(transforms)


```


For the skewed distributions of **K** Potassium, **Ba** Barium, **Fe** Iron, it is observed that there is some improvement with square root transformation of **K**, **Ba** and **Fe** variables.
I will go ahead and do these to explore them in models.


```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Transformation applied to these three predictor variables

traindataorig$K.sqrt <- sqrt(traindataorig$K)
hist(sqrt(traindataorig$K)) # select this


traindataorig$Ba.sqrt<-sqrt(traindataorig$Ba)
hist(sqrt(traindataorig$Ba))


traindataorig$Fe.sqrt<-sqrt(traindataorig$Fe)
hist(sqrt(traindataorig$Fe))


#RI no transformation
#View(traindataorig)

```

Now that our data is ready to model, we will divide it into training (70% ) and test sets (30%)

```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


set.seed(21)
randomobs <- sample(seq_len(nrow(traindataorig)), size = floor(0.7 * nrow(traindataorig)))

trainnew <- traindataorig[randomobs,]
testnew <- traindataorig[-randomobs,]

```


***********
\newpage



## Building Models

I shall use the split training dataset (70%) of observations to build the models.

### Model 1 Multinomial Regression 

As the first model, I will build the multinomial logistic regression model. 
All the predictors are considered. The transformed ones of **K, Ba, Fe** replace the original ones.
GlassType 1 is considered the baseline.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}

library(nnet)
trainnew$GTF <- factor(trainnew$GlassType)
trainnew$out <- relevel(trainnew$GTF, ref="1")


#View(trainnew)

model1.multi <- multinom(out~RI + Na + Mg +Al + Si + K.sqrt + Ca + Ba.sqrt + Fe.sqrt , data=trainnew)
#print(model1.multi)
sum_model1 <- summary(model1.multi)
sum_model1


# Applying model to test data

testnew$GTF <- factor(testnew$GlassType)

predval <- predict(model1.multi, testnew)
confmt <- table(predval, testnew$GTF)
confm1 <- confusionMatrix(predval, testnew$GTF)
testnew$outm1 <- predval

confm1
#View(testnew)

Misce1 <- 1-sum(diag(confmt))/sum(confmt)
ztest <- sum_model1$coefficients/sum_model1$standard.errors
p <- (1- pnorm(abs(ztest),0,1))*2
p


model1cf_p1 <- as.data.frame(confm1$overall)
model1cf_p2 <- as.data.frame(confm1$byClass)
colnames(model1cf_p1) <- 'Model1'
colnames(model1cf_p2) <- 'Model1'

coefficients(model1.multi)

# Finding AIC and BIC

aicm1 <- AIC(model1.multi)
bicm1 <- BIC(model1.multi)

```

Glass Type 1 is the baseline reference level.

It is observed here that RI Refractive Index has a positive and very high coefficient for GlassType 2, where as it is negatively impacting Type 3 and 5.
However its significance is high as seen from p values.

The presence of Na, sodium is not of much significance for Type in identifying any of the Glass Type except for Type 3,5,7. It has high significane for Type 3 (low coefficient)and Type 6(positive high coefficeint) glass.

Mg, Magnesium is observed to have high significance for Type 2 ,6,7, Has negative coefficeints.

Al,Aluminium has very high coefficeint for Type 6 and high significance for Type 5, 6
Si hold statistical significance for Type 2, 5

Potassium K, Barium (high coefficient), Calcium hold significance for Type 6

Potassium also significant in identifying Type 2,7

The accuracy of the model is 70%

```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}

par(mfrow=c(1,2))

pander(ftable(confm1$table), caption="Confusion Matrix :Model 1 Multinomial Logistic Regression")

```



### Model 2 Random Forest



The "caret" package train function is used with method of "random forest"" .
A 5 fold cross validation is used.
From the summary we see that for 2 mtry (number of variables used ), we get the highest accuracy of 86%

From the plot of the fit, we observe how the accuracy decreases as the predictors increase..

The top impacting predictor variables that give the best performance (highest accuracy are plotted in the Variable Importance Plot below. The plot shows the importance per Glass Type )category



```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}



model2.rf <- train(out ~ RI + Na + Mg +Al + Si + K.sqrt + Ca + Ba.sqrt + Fe.sqrt, data=trainnew, method="rf", trControl=trainControl(method="cv",number=5), prox=TRUE, importance = TRUE, allowParallel=TRUE)

# show the model summary          
sum_model2<-summary(model2.rf)
print(model2.rf)

# Crossvalidating for test model
predval <- predict(model2.rf, testnew)
confmt <- table(predval, testnew$GTF)
confm2 <- confusionMatrix(predval, testnew$GTF)
testnew$outm2 <- predval

confm2
#View(testnew)

Misce2 <- 1-sum(diag(confmt))/sum(confmt)

model2cf_p1 <- as.data.frame(confm2$overall)
model2cf_p2 <- as.data.frame(confm2$byClass)
colnames(model2cf_p1) <- 'Model2'
colnames(model2cf_p1) <- 'Model2'

coefficients(model2.rf)


plot(model2.rf, main = "Error rate of random forest")

## variable importance
rfImp <- varImp(model2.rf)
rfImp
plot(rfImp,top = 20,  main = "Importance of Variables")

pander(ftable(confm2$table), caption="Confusion Matrix :Model 2 Random Forest Model")

```



The variable importance plot is a critical output of the random forest algorithm. For each variable in your matrix it tells you how important that variable is in classifying the data. The plot shows each variable on the y-axis, and their importance on the x-axis. They are ordered top-to-bottom as most- to least-important.

Although the importance of variables is varying across the glass types , it is observed that Mg , Magnesium is the top player among all (topmost important for Type 5,2,3 and second topmost for 1,6,7)

Similarly, Refreactive Index helps in identification for window and vehicle appplication glasses. Potassium seems to be of mediocre importance for all types.

Aluminium has no importance for tableware glassbut quite important for Type 5 container, and in Type 1,2,3 ie window/vehicle glasses

Si is of impotance in window glasses.





### Model 3 Conditional Inference Tree


This model will same predictor set as the earlier two models. Party package ctree function is used for this model.


```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}


library(party)
Fmla <- out ~ RI + Na + Mg +Al + Si + K.sqrt + Ca + Ba.sqrt + Fe.sqrt
model3.tree <-  ctree(Fmla, data = trainnew)
plot(model3.tree, type= "simple")

# show the model summary          
sum_model3 <- summary(model3.tree)
sum_model3
print(model3.tree)

# Crossvalidating for test model
predval <- predict(model3.tree, testnew)
confmt <- table(predval, testnew$GTF)
confm3 <- confusionMatrix(predval, testnew$GTF)
testnew$outm3 <- predval

confm3

#View(testnew)

Misce3 <- 1-sum(diag(confmt))/sum(confmt)

model3cf_p1 <- as.data.frame(confm3$overall)
model3cf_p2 <- as.data.frame(confm3$byClass)
colnames(model3cf_p1) <- 'Model3'
colnames(model3cf_p2) <- 'Model3'

pander(ftable(confm3$table), caption="Confusion Matrix : Model 3 Conditional Inference Tree Model")

```

The dataset is here partitioned into two subsets based on Mg content for values > 2.2 and <= 2.2.

Either of the branches are further split based on other chemical constituents. The greater than 2.2 Mg content group is further analyzed for Al , Aluminium content based on Al avlues of <=1.4 or >1.4.

The key point is that every record in the dataset is ultimately assigned to one of the  terminal nodes of this tree (the "leaves," numbered 4,5,8,11,12,13 and 13).  The numbers associated with these nodes gives their size and the fraction of each glass type which may be viewed as an estimate of the conditional probability. 

Although the model determines the important predictors similar to Randome forest , for Mg , Al,  it is not upto mark with only 67% accuracy.


### Model 4 Linear Discriminant Analysis

I will proceed with LDA model as the fourth model for classification of glasstypes

```{r tidy=TRUE, tidy.opts=list(width.cutoff=150)}


model4.lda <- train(out ~ RI + Na + Mg +Al + Si + K.sqrt + Ca + Ba.sqrt + Fe.sqrt, data=trainnew,
             method='lda', 
             preProcess=c('scale', 'center'))

sum_model4 <- summary(model4.lda)



# Crossvalidating for test model
predval <- predict(model4.lda, testnew)
confmt <- table(predval, testnew$GTF)
confm4 <- confusionMatrix(predval, testnew$GTF)
testnew$outm <- predval

confm4

#View(testnew)

Misce4 <- 1-sum(diag(confmt))/sum(confmt)

model4cf_p1 <- as.data.frame(confm4$overall)
model4cf_p2 <- as.data.frame(confm4$byClass)
colnames(model4cf_p1) <- 'Model4'
colnames(model4cf_p2) <- 'Model4'

pander(ftable(confm4$table), caption="Confusion Matrix : Model 4 Linear Discriminant Analysis")
#multiclass.roc(testnew$GTF, predict(model4.lda, testnew, type = response))
```


LDA seems to be giving the worst accuracy of only 58%.


\newpage 


## Model Selection and Inference:


From the four models derived above, we look at the performance of each of these through cross validation,  with respect to the Accuracy in classification.
Form the comparison table below we see that highest Accuracy, least misclassification error is  delivered by Random Forest Model is the highest.

The Factors most impacting the GlassType are Magnesium, Calcium, Aluminium and Refractive Index, Potassium although others are significant to smaller extent.


Since there is no evaluation dataset, the test (30% of randomly selected observations from original data) are written to *predicted_glasstypes.csv*

*Note :* outm1,outm2,outm3,outm4 are the predictions of each Model1 , Model2, Model3 , Model4

GTF : Factored GlassType

GlassType : Response Variable



**Confusion Matrix Metrics For All Models**


```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}


cfmatmetricsdf <- cbind(model1cf_p1,model2cf_p1,model3cf_p1,model4cf_p1)
kable(cfmatmetricsdf,caption='Confusion Matrix Metrics For All Models')

#cfmatmetricsdf2 <- cbind(model1cf_p2,model2cf_p2,model3cf_p2,model4cf_p2)
#kable(cfmatmetricsdf2,caption='Confusion Matrix Metrics For All Models')


```



**Comparison For All Models**

```{r tidy=TRUE, tidy.opts=list(width.cutoff=80)}

# Misclassification Error For All Models
MCEAll <- rbind(Misce1, Misce2, Misce3, Misce4) %>% round(2)


comptable <- cbind(MCEAll)

rownames(comptable) <- c("Model 1", "Model 2", "Model 3", "Model 4")
colnames(comptable) <- c( "MCE")

pander(comptable,caption = 'Model Comparison: MisClassification Error')



write.csv(testnew, 'predicted_glasstypes.csv')
```


### Reference :

http://www.asdlib.org/onlineArticles/elabware/thompson/Glass/Glass(RI)PFaculty.pdf

https://en.wikipedia.org/wiki/Glass

http://www.cmog.org/article/chemistry-glass

http://www.britglass.org.uk/alkali-barium-silicate-glass


#### *The CrystalGazer's Visions Have Flashed !!*


